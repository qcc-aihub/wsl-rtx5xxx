#!/usr/bin/env python3
"""
PyTorchå®‰è£…éªŒè¯è„šæœ¬

éªŒè¯PyTorchæ˜¯å¦æ­£ç¡®å®‰è£…å¹¶èƒ½å¤Ÿä½¿ç”¨GPU
å¯é€‰æ‹©æ˜¯å¦åŠ è½½å®é™…æ¨¡å‹è¿›è¡ŒéªŒè¯
"""

import argparse
import sys

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="PyTorchå®‰è£…éªŒè¯è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  %(prog)s                    # åŸºç¡€éªŒè¯ï¼ˆä¸åŠ è½½æ¨¡å‹ï¼‰
  %(prog)s --load-model       # å®Œæ•´éªŒè¯ï¼ˆåŒ…æ‹¬åŠ è½½å®é™…æ¨¡å‹ï¼‰
  %(prog)s --model-name BAAI/bge-reranker-base  # æŒ‡å®šæ¨¡å‹åç§°
        """
    )
    
    parser.add_argument(
        "--load-model",
        action="store_true",
        help="åŠ è½½å®é™…æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼ˆéœ€è¦ç½‘ç»œè¿æ¥ä¸‹è½½æ¨¡å‹ï¼‰"
    )
    
    parser.add_argument(
        "--model-name",
        default="BAAI/bge-reranker-base",
        help="æŒ‡å®šè¦åŠ è½½çš„æ¨¡å‹åç§°ï¼ˆé»˜è®¤: BAAI/bge-reranker-baseï¼‰"
    )
    
    return parser.parse_args()


def verify_pytorch():
    """éªŒè¯PyTorchå®‰è£…"""
    print("ğŸ” éªŒè¯PyTorchå®‰è£…...")
    
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
            print(f"âœ… CUDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
            print(f"âœ… æ£€æµ‹åˆ° {torch.cuda.device_count()} ä¸ªGPUè®¾å¤‡")
            
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
                
            # ç®€å•çš„GPUæµ‹è¯•
            print("\nğŸ§ª æ‰§è¡Œç®€å•çš„GPUæµ‹è¯•...")
            x = torch.randn(1000, 1000).cuda()
            y = torch.randn(1000, 1000).cuda()
            z = torch.matmul(x, y)
            print(f"âœ… GPUè®¡ç®—æµ‹è¯•é€šè¿‡: {z.shape}")
            
        else:
            print("âŒ CUDAä¸å¯ç”¨")
            
    except ImportError as e:
        print(f"âŒ PyTorchå¯¼å…¥å¤±è´¥: {e}")
        return False
        
    try:
        import torchvision
        print(f"âœ… TorchVisionç‰ˆæœ¬: {torchvision.__version__}")
    except ImportError:
        print("âŒ TorchVisionæœªå®‰è£…")
        
    try:
        import torchaudio
        print(f"âœ… TorchAudioç‰ˆæœ¬: {torchaudio.__version__}")
    except ImportError:
        print("âŒ TorchAudioæœªå®‰è£…")
        
    return True


def verify_model_loading(model_name: str):
    """éªŒè¯æ¨¡å‹åŠ è½½åŠŸèƒ½"""
    print(f"\nğŸ¤– éªŒè¯æ¨¡å‹åŠ è½½åŠŸèƒ½: {model_name}")
    
    try:
        print("ğŸ“¦ æ­£åœ¨å¯¼å…¥sentence-transformers...")
        from sentence_transformers import CrossEncoder
        
        print(f"â¬‡ï¸  æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name}")
        print("   (é¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...)")
        
        model = CrossEncoder(model_name)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # æµ‹è¯•æ¨¡å‹æ¨ç†
        print("\nğŸ§ª æµ‹è¯•æ¨¡å‹æ¨ç†...")
        test_pairs = [('å¦‚ä½•ç”³è¯·ä¿¡ç”¨å¡ï¼Ÿ', 'æ€ä¹ˆåŠç†ä¿¡ç”¨å¡ï¼Ÿ')]
        scores = model.predict(test_pairs)
        print(f"âœ… æ¨¡å‹æ¨ç†æµ‹è¯•é€šè¿‡!")
        print(f"   ç¤ºä¾‹åˆ†æ•°: {scores[0]:.4f}")
        
        return True
        
    except ImportError as e:
        print(f"âŒ sentence-transformerså¯¼å…¥å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…sentence-transformers: pip install sentence-transformers")
        return False
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½æˆ–æ¨ç†å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    # åŸºç¡€PyTorchéªŒè¯
    pytorch_success = verify_pytorch()
    
    if not pytorch_success:
        print("\nâŒ PyTorchåŸºç¡€éªŒè¯å¤±è´¥")
        sys.exit(1)
    
    # å¦‚æœç”¨æˆ·é€‰æ‹©åŠ è½½æ¨¡å‹éªŒè¯
    model_success = True
    if args.load_model:
        model_success = verify_model_loading(args.model_name)
    
    # æ€»ç»“
    print(f"\n{'='*50}")
    if pytorch_success and model_success:
        print("ğŸ‰ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼")
        if args.load_model:
            print("âœ… PyTorchç¯å¢ƒå’Œæ¨¡å‹åŠ è½½åŠŸèƒ½éƒ½æ­£å¸¸å·¥ä½œ")
        else:
            print("âœ… PyTorchç¯å¢ƒéªŒè¯å®Œæˆ")
            print("ğŸ’¡ å¦‚éœ€éªŒè¯æ¨¡å‹åŠ è½½åŠŸèƒ½ï¼Œè¯·è¿è¡Œ: python3 verify_pytorch.py --load-model")
    else:
        print("âŒ éªŒè¯å¤±è´¥")
        sys.exit(1)

if __name__ == "__main__":
    main()
